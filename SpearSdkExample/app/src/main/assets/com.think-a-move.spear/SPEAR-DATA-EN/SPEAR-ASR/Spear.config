################################################################################
## System Settings ##
################################################################################
--apply-speaker-adaptation=false ## Whether to apply speaker adaptation
                                 ## (bool, default = false)
--samp-freq=16000          ## audio input sample frequency
                           ## (float, default = 16000, [16000 | 8000])
--n-best=1                 ## maximum number of hypothesis returned from decoder
                           ## (int, default = 1, [1,∞])
--intermediate-nbest=1     ## maximum number of intermediate hypothesis
                           ## returned from decoder (int, default = 1, [1,∞])
--intermediate-interval=10 ## Interval at which to return intermediate result
                           ## unit is 10ms, (int, default = 10, [1,∞])
--verbose=-1               ## Verbose level (int, default = 0, [-1, 3])
--print-args=false         ## Print the command line arguments
                           ## (bool, default = true)
--debug-mode=false         ## if true, more memory will be used to hold things
                           ## for debug purpose (bool, default = false)
--tagging-fst=             ## Basenames of tagging fsts seperated by ','
                           ## corresponding fst need to be placed at data/models
                           ## recognition result will be in XML format
--decoder-type=lattice-faster-online-decoder ## decoder type
                           ## (string, default = lattice-faster-online-decoder)
                           ## available:[lattice-faster-online-decoder,faster-decoder]
--save-lattice=false       ## If true, lattice will be saved in memory
                           ## (bool, default = false)
--use-rnn-rescore=false    ## If true, RNNLM will be used to rescore results
                           ## (bool, default = false)
--case-preference=upper    ## Determine character case of speech recognition output
		                   ## lower means lower-case, upper means upper-case, raw means no case regulation.
		                   ## (string, default = upper, [upper, lower, raw])
--use-mbr-decode=false     ## If set true, additonal Minimum Bayes Risk decoding will be used
                           ## to replace the original commit score(average of likelihood) with confidence score.
                           ## This will only work for n-best=1 and use-rnn-rescore=false
                           ## (bool, default = false)
--pure-tagging=false       ## This parameter will be used when tagging-fst is assgined with values.
                           ## If set false, output will contain both original result and all the tagged results using all the specified fsts.
                           ## If set true, output will only contain the tagged result from the first specified tagging-fst.
################################################################################
## Decoder Settings(Faster decoder) ##
################################################################################
--faster-decoder.beam=30.0                 ## Decoding beam
                            ## Larger->slower, more accurate, more comsumption
                            ## (float, default = 16, [10,∞])
--faster-decoder.max-active=10000          ## Decoder max active states, more comsumption
                            ## Larger->slower, more accurate
                            ## (int, default=numeric_limits<int32>::max(),[0,∞])
--faster-decoder.min-active=200            ## Decoder minimum #active states
                            ## (int, default = 200,[0,∞])
--faster-decoder.hash-ratio=2.0            ## Control expanding the HashList during decoding
                            ## (float, default = 2, [1.0,∞])
--faster-decoder.beam-delta=0.5            ## Increment used in decoding，obscure and　relates
                            ## to a speedup in the way the max-active
                            ## constraintis　applied. Larger is more accurate.
                            ## (float, default = 0.5)
################################################################################
## Decoder Settings(Lattice Faster decoder) ##
################################################################################
--lattice-faster-decoder.beam=30.0                 ## Decoding beam
                            ## Larger->slower, more accurate, more comsumption
                            ## (float, default = 16, [10,∞])
--lattice-faster-decoder.lattice-beam=2.0          ## Lattice generation beam used when n-best > 1
                            ## Larger->slower (float, default = 10, [0,∞])
--lattice-faster-decoder.prune-interval=25         ## Interval at which to prune tokens
                            ## unit is 10ms, (int, default = 25, [1,∞])
--lattice-faster-decoder.max-active=10000          ## Decoder max active states, more comsumption
                            ## Larger->slower, more accurate
                            ## (int, default=numeric_limits<int32>::max(),[0,∞])
--lattice-faster-decoder.min-active=200            ## Decoder minimum #active states
                            ## (int, default = 200,[0,∞])
--lattice-faster-decoder.hash-ratio=2.0            ## Control expanding the HashList during decoding
                            ## (float, default = 2, [1.0,∞])
--lattice-faster-decoder.beam-delta=0.5            ## Increment used in decoding，obscure and　relates
                            ## to a speedup in the way the max-active
                            ## constraintis　applied. Larger is more accurate.
                            ## (float, default = 0.5)
--lattice-faster-decoder.determinize-lattice=true  ## If true, determinize the lattice
                            ## keeping best pdf-sequence for each word-sequence
                            ## (bool, default = true)
--lattice-faster-decoder.delta=0.000976562         ## Tolerance used in determinization
                            ## (float, default = 0.000976562)
--lattice-faster-decoder.max-mem=50000000          ## Maximum approximate memory usage in determinization
                        ## (real usage might be many times this)
                        ## (int, default = 50000000)
--lattice-faster-decoder.minimize=false        ## If true, push and minimize after determinization.
                        ## (bool, default = false)
--lattice-faster-decoder.phone-determinize=true## If true, do an initial pass of determinization on
                        ## both phones and words (see also --word-determinize)
                        ## (bool, default = true)
--lattice-faster-decoder.word-determinize=true ## If true, do a second pass of determinization on words
                        ## only (see also --phone-determinize)
                        ## (bool, default = true)
################################################################################
## End-Pointing(EP) Settings - General ##
################################################################################
--vad-chunk-length-sec=0.03         ## Audio unit processed by EP, in seconds
                                    ## (float, default = 0.03, (0.0, ∞])
--passive-cache-size=20             ## Silence audio units(10ms) saved in cache
                                    ## (int, default = 20, [1, ∞])
################################################################################
## End-Pointing Settings - Method 1 VAD ##
################################################################################
--vad-type=nnet3            ## VAD model type
                            ## (string, default = "nnet3"，
                            # [webrtc | nnet3 | lattice | none])
--vad-for-start=true        ## switch to use VAD for start pointing Control
                            ## (bool, default = true)
--vad-for-end=true          ## switch to use VAD for end pointing Control
                            ## (bool, default = true)
--do-vad-smoothing=true     ## if ture, VAD will be smoothed by median filter
                            ## (bool, default = true)
--smoothing-window-size=10  ## size of median filter for smoothing VAD result
                            ## (int, default = 19, [3, ∞])
--passive-consistency-threshold=20  ## consecutive silence audio units(10ms)
                                    ## treating as end signal
                                    ## (int, default = 20, [1, ∞])
--min-trailing-silence=0.25 ## duration of trailing silence (seconds)
                            ## to restart the decoder when using lattice vad
                            ## (float, default = 0.25, [0.05, ∞])
--min-unchanged-frames=25   ## successive frames with the same results
                            ## to restart the decoder when using lattice vad
                            ## (int, default = 25, [1, ∞])
################################################################################
## End-Pointing Settings - Method 2 Viterbi ##
################################################################################
--do-endpointing=false              ## If true, match of any of the following
                                    ## rules will be marked as end-point
                                    ## (bool, default = false)
--endpoint.silence-phones=1:2:3     ## List of phones that are considered to be
                                    ## silence phones by the endpointing code
                                    ## (string, default = "")
## Each Rule is satisfied when its own four requirements are met.
## rule1 times out after 5 seconds of silence, even if we decoded nothing.
--endpoint.rule1.must-contain-nonsilence=false ## If true, there must be non-sil
                                               ## in the best-path traceback.
                                               ## (bool, default = false)
--endpoint.rule1.min-trailing-silence=5.0      ## Duration of trailing silence
                                               ## (seconds) to be >= this value.
                                               ## (float, default = 5)
#--endpoint.rule1.max-relative-cost=inf        ## relative-cost of final-states
                                               ## to be <= this value
                                   ## (float, default = <BaseFloat>::infinity())
--endpoint.rule1.min_utterance_length=0.0      ## utterance-length (in seconds)
                                               ## to be >= this value.
                                               ## (float, default = 0.0)
## rule2 times out after 0.5 seconds of silence if we reached the final-state
## with good probability (relative_cost < 2.0) after decoding something.
--endpoint.rule2.must-contain-nonsilence=true  ## If true, there must be non-sil
                                               ## in the best-path traceback.
                                               ## (bool, default = true)
--endpoint.rule2.min-trailing-silence=0.5      ## Duration of trailing silence
                                               ## (seconds) to be >= this value.
                                               ## (float, default = 0.5)
--endpoint.rule2.max-relative-cost=2.0         ## relative-cost of final-states
                                               ## to be <= this value
                                               ## (float, default = 2)
--endpoint.rule2.min_utterance_length=0.0      ## utterance-length (in seconds)
                                               ## to be >= this value.
                                               ## (float, default = 0.0)
## rule3 times out after 1.0 seconds of silence if we reached the final-state
## with OK probability (relative_cost < 8.0) after decoding something
--endpoint.rule3.must-contain-nonsilence=true  ## If true, there must be non-sil
                                               ## in the best-path traceback.
                                               ## (bool, default = true)
--endpoint.rule3.min-trailing-silence=1.0      ## Duration of trailing silence
                                               ## (seconds) to be >= this value.
                                               ## (float, default = 1.0)
--endpoint.rule3.max-relative-cost=8.0         ## relative-cost of final-states
                                               ## to be <= this value
                                               ## (float, default = 8)
--endpoint.rule3.min_utterance_length=0.0      ## utterance-length (in seconds)
                                               ## to be >= this value.
                                               ## (float, default = 0.0)
## rule4 times out after 2.0 seconds of silence after decoding something,
## even if we did not reach a final-state at all.
--endpoint.rule4.must-contain-nonsilence=true  ## If true, there must be non-sil
                                               ## in the best-path traceback.
                                               ## (bool, default = true)
--endpoint.rule4.min-trailing-silence=2.0      ## Duration of trailing silence
                                               ## (seconds) to be >= this value.
                                               ## (float, default = 2.0)
#--endpoint.rule4.max-relative-cost=inf        ## relative-cost of final-states
                                                ## to be <= this value
                                   ## (float, default = <BaseFloat>::infinity())
--endpoint.rule4.min_utterance_length=0.0      ## utterance-length (in seconds)
                                               ## to be >= this value.
                                               ## (float, default = 0.0)
## rule5 times out after the utterance is 20 seconds long, regardless of
## anything else.
--endpoint.rule5.must-contain-nonsilence=false ## If true, there must be non-sil
                                               ## in the best-path traceback.
                                               ## (bool, default = false)
--endpoint.rule5.min-trailing-silence=0.0      ## Duration of trailing silence
                                               ## (seconds) to be >= this value.
                                               ## (float, default = 0.0)
#--endpoint.rule5.max-relative-cost=inf        ## relative-cost of final-states
                                               ## to be <= this value
                                   ## (float, default = <BaseFloat>::infinity())
--endpoint.rule5.min_utterance_length=20.0     ## utterance-length (in seconds)
                                               ## to be >= this value.
                                               ## (float, default = 20.0)
################################################################################
## Grammar on the fly Settings##
################################################################################
--g2p-abbreviation-threshold=5 ##If word doesn't exist in the dictionary and its
                               ##length is shorter than threshold, word will also
                               ##be treated as abbreviation.
                               ##(int, default = 5)
--predefined-labels=           ##A list of Basenames of label fsts seperated by ','
                               ##If assigned, fsts will be loaded as predefined labels.
--allow-incomplete-command=false##Allow partial valid command to be recognized
                                ##(bool, default = false)
--allow-garbage-inside-command=false##Allow garbage talking inside valid command.
                                    ##(bool, default = false)
--g2p-nbest=1        ## number of pronunciations generated for unknown words
                     ## (int, default = 1, [1, ∞])
--sil-prob=0.99      ## Probability of silence between words
                     ## (including at the beginning and endof word sequences)
                     ## (float, default = 0.5, (0.0, 1.0))
--remove-oov=false   ## If true, any paths containing the OOV symbol are removed
                     ## (bool, default = false)
--oov-word=<UNK>     ## Symbol of oov word
                     ## (string, default = "<UNK>")
--map-oov=           ## If assigned, all the oovs will be mapped to this symbol.
                     ## (string, default = "")
--self-loop-scale=1  ## Scale for self-loop probabilities relative to LM
                     ## (float, default = 1)
################################################################################
## RNNLM Settings##
################################################################################
--lm-scale=-1               ## Scaling factor for original language model costs
                            ## (float, default=-1)
--rnn-lm-scale=0.5          ## Scaling factor for rnn language model costs
                            ## (float, default=0.5)
--num-states-cache=50000    ## Number of states we cache when mapping LM FST to lattice type.
                            ## More -> more memory but faster.
                            ## (int, default=50000)
--max-ngram-order=4         ## If positive, limit the rnnlm context to the given number,
                            ## -1 means we are not going to limit it.
                            ## (int, default=4)
--debug-computation=false   ## If true, turn on debug for the actual computation (very verbose!)
                            ## (bool, defaul=false)
--normalize-probs=false     ## probabilities will be correctly normalized
                            ## (otherwise the sum-to-one normalization is approximate)
                            ## (bool, defaul=false)
################################################################################
## Settings not support yet(Do not modify this section) ##
################################################################################
--asr-model=JL3a-16k-NA     ## Acoustic Model version name
                            ## (string, default = "JL3a-16k-NA")
--vad-model=vad-1b          ## VAD Model version name
                            ## (string, default = "vad-1b")
--lexicon=English-1a        ## lexicon version name
                            ## (string, default = "English-1a")
--garbage-lexicon=English-2a## Garbage lexicon version name
                            ## (string, default = "English-1a")
--g2p-model=English-2       ## G2p Model version name
                            ## (string, default = "English-1")
--rnn-model=lstm-tdnn-1a    ## RNN Model version name
                            ## (string, default = "lstm-tdnn-1a")
--do-speaker-track=false    ## if true, Speaker diarisation will be applied
                            ##(bool, default = false)
################################################################################
## Model Settings(Do not modify this section) ##
################################################################################
--base-model.acoustic-scale=1.0  ## Scaling factor for acoustic log-likelihoods
                                  ## (float, default = 0.1)
--base-model.extra-left-context-initial=0 ## Extra left context to use at the
                                           ## first frame of an utterance (note:
                                           ## this will just consist of repeats
                                           ## of the first frame, and should not
                                           ## usually be necessary.
                                           ## (int, default = 0)
--base-model.feature-type=mfcc  ## Base feature type [mfcc, plp, fbank]
                                 ## (string, default = "mfcc")
--base-model.frame-subsampling-factor=3  ##Required if the frame-rate of output
                                          ##(e.g. in 'chain' models) is less than
                                          ## frame-rate of the original alignment.
                                          ##(int, default = 1)
--base-model.frames-per-chunk=20  ## Number of frames in each chunk that is
                                   ## separately evaluated by the neural net.
                                   ## Measured before any subsampling,
                                   ## if the --frame-subsampling-factor options
                                   ## is used (i.e. counts input frames.  This is
                                   ## only advisory (may be rounded up if needed.
                                   ## (int, default = 20)
--base-model.mfcc-config=data/conf/mfcc.conf ## Config file for MFCC features
                                              ## (e.g. conf/mfcc.conf)
                                              ## (string, default = "")
--base-model.ivector-extraction-config=data/conf/ivector_extractor.conf
                                ## Configuration file for online iVector extraction
                                ## (string, default = "")
--vad-model.acoustic-scale=1.0  ## Scaling factor for acoustic log-likelihoods
                                 ## (float, default = 0.1)
--vad-model.extra-left-context-initial=0  ##Extra left context to use at the
                                           ##first frame of an utterance ( this
                                           ##will just consist of repeats of first
                                           ##frame, shouldn't usually be necessary
                                           ## (int, default = 0)
--vad-model.feature-type=mfcc  ## Base feature type [mfcc, plp, fbank]
                                ## (string, default = "mfcc")
--vad-model.frame-subsampling-factor=3 ##Required if the frame-rate of output
                                        ##(e.g. in 'chain' models) is less than
                                        ##frame-rate of the original alignment.
                                        ## (int, default = 1)
--vad-model.frames-per-chunk=20  ## Number of frames in each chunk that is
                                  ## separately evaluated by the neural net.
                                  ## Measured before any subsampling,
                                  ## if the --frame-subsampling-factor options
                                  ## is used (i.e. counts input frames.  This is
                                  ## only advisory (may be rounded up if needed.
                                  ## (int, default = 20)
--vad-model.mfcc-config=data/conf/mfcc.conf ## Config file for MFCC features
                                                 ## (e.g. conf/mfcc.conf)
                                                 ## (string, default = "")
--brk-symbol=152217
--eos-symbol=152216
--bos-symbol=152215
--g2p-grapheme-case=upper  ## Grapheme case requirement for g2p input
                         ## lower means lower case, upper means upper case, raw means not appliable
                         ## (string, default = raw, [upper, lower, raw])
--g2p-language=english  ## Specify Language of g2p model.
--garbage-words=<UNK>,<NOISE>   ## A list of garbage words added for grammar-on-the-fly.
                                    ## Words are separated by commas.
                                ## (string, default = "<UNK>,<NOISE>")
--ignored-symbols=<UNK>,<NOISE>   ## A list of symbols ignored in recognition result.
                                    ## Words are separated by commas.
                                ## (string, default = "<UNK>,<NOISE>")
--unk-symbols=<UNK1>,<UNK2>,<UNK3>,<UNK4>,<UNK5>,<UNK6>,<UNK7>,<UNK8>,<UN9>
                     ## A list of symbols converted to <UNK> in recognition result.
                     ## Words are separated by commas. (string, default =
                     ## "<UNK1>,<UNK2>,<UNK3>,<UNK4>,<UNK5>,<UNK6>,<UNK7>,<UNK8>,<UN9>")
--sil-phone=SIL      ## Text form of optional-silence phone, e.g. 'SIL'.
                     ## (string, default = "SIL")
################################################################################
##Hidden Settings(Only display base-model, vad-model has the exact same set)##
################################################################################
##--base-model.add-pitch    ## Append pitch features to raw MFCC/PLP/filterbank
                           ## features [but not for iVector extraction]
                           ## (bool, default = false)
##--base-model.computation.debug ##If true, turn on debug for the neural net
                                ## computation (very verbose!) Will be turned on
                                ## regardless if --verbose >= 5
                                ## (bool, default = false)
##--base-model.debug-computation ## If true, turn on debug for the actual
                                ## computation (very verbose!)
                                ## (bool, default = false)
##--base-model.fbank-config  ## Configuration file for filterbank features
                            ## (string, default = "")
##--base-model.ivector-silence-weighting.max-state-duration
                            ## (RE weighting in iVector estimation for online
                            ##decoding) Maximum allowed duration of a single
                            ##transition-id runs with durations longer than this
                            ##will be weighted down to the silence-weight.
                            ## (float, default = -1)
##--base-model.ivector-silence-weighting.silence-phones
                            ## (RE weighting in iVector estimation for online
                            ## decoding) List of integer ids of silence phones,
                            ## separated by colons (or commas). Data that
                            ##(according to the traceback of the decoder)
                            ##corresponds to these phones will be downweighted
                            ##by --silence-weight.
                            ## (string, default = "")
##--base-model.ivector-silence-weighting.silence-weight :
                            ## (RE weighting in iVector estimation for online
                            ## decoding) Weighting factor for frames that the
                            ## decoder trace-back identifies as silence; only
                            ## relevant if the --silence-phones option is set.
                            ## (float, default = 1)
##--base-model.online-pitch-config ##Configuration file for online pitch features
                                  ##if --add-pitch=true
                                  ## (string, default = "")
##--base-model.optimization.allocate-from-other
                                  ##Instead of deleting a matrix of a given size
                                  ##and then allocating a matrix of the same
                                  ##size, allow re-use of that memory
                                  ## (bool, default = true)
##--base-model.optimization.allow-left-merge ##Set to false to disable
                                            ##left-merging of variables in
                                            ##remove-assignments(obscure option)
                                            ## (bool, default = true)
##--base-model.optimization.allow-right-merge ## Set to false to disable
                                             ##right-merging of variables in
                                             ##remove-assignments (obscure option)
                                             ## (bool, default = true)
##--base-model.optimization.backprop-in-place ##Set to false to disable
                                             ##optimization that allows
                                             ##in-place backprop
                                             ## (bool, default = true)
##--base-model.optimization.consolidate-model-update
                                             ##Set to false to disable
                                             ##optimization that consolidates
                                             ##model-update phase of backprop
                                             ##(e.g. for recurrent architectures
                                             ## (bool, default = true)
##--base-model.optimization.convert-addition ##Set to false to disable the
                                            ##optimization that converts
                                            ##Add commands into Copy commands
                                            ## wherever possible.
                                            ## (bool, default = true)
##--base-model.optimization.extend-matrices ##This optimization can reduce memory
                                           ## requirements for TDNNs when
                                           ## applied together with
                                           ## --convert-addition=true
                                           ## (bool, default = true)
##--base-model.optimization.initialize-undefined ##Set to false to disable
                                                ##optimization that avoids
                                                ##redundant zeroing
                                                ## (bool, default = true)
##--base-model.optimization.max-deriv-time ##You can set this to the maximum t
                                          ##value that you want derivatives to
                                          ##be computed at when updating the
                                          ## model. This is an optimization that
                                          ## saves time in the backprop phase
                                          ## for recurrent frameworks
                                          ## (int, default = <int32>::max())
##--base-model.optimization.max-deriv-time-relative
   ##An alternative mechanism for setting the --max-deriv-time,
   ##suitable for situations where the length of the egs is variable.
   ## If set, it is equivalent to setting the --max-deriv-time to this value
   ## plus the largest 't' value in any 'output' node of the computation request
   ## (int, default = <int32>::max())
##--base-model.optimization.memory-compression-level :
    ##This is only relevant to training, not decoding.  Set this to 0,1,2;
    ## higher levels are more aggressive at reducing memory by compressing
    ##quantities needed for backprop, potentially at the expense of speed and
    ##the accuracy of derivatives.  0 means no compression at all;
    ##1 means compression that shouldn't affect results at all.
    ## (int, default = 1)
##--base-model.optimization.min-deriv-time
    ##You can set this to the minimum t value that you want derivatives to be
    ##computed at when updating the model.  This is an optimization that saves
    ##time in the backprop phase for recurrent frameworks
    ##(int, default = <int32>::min())
##--base-model.optimization.move-sizing-commands
    ##Set to false to disable optimization that moves matrix allocation
    ## and deallocation commands to conserve memory.
    ## (bool, default = true)
##--base-model.optimization.optimize
    ##Set this to false to turn off all optimizations
    ## (bool, default = true)
##--base-model.optimization.optimize-row-ops
    ## Set to false to disable certain optimizations that
    ## act on operations of type *Row*.
    ## (bool, default = true)
##--base-model.optimization.propagate-in-place
    ## Set to false to disable optimization that allows in-place propagation
    ## (bool, default = true)
##--base-model.optimization.remove-assignments
    ## Set to false to disable optimization that removes redundant assignments
    ## (bool, default = true)
##--base-model.optimization.snip-row-ops
    ## Set this to false to disable an optimization that
    ## reduces the size of certain per-row operations
    ## (bool, default = true)
##--base-model.optimization.split-row-ops
    ## Set to false to disable an optimization that may replace some operations
    ## of type kCopyRowsMulti or kAddRowsMulti with up to two simpler operations
    ## (bool, default = true)
##--base-model.plp-config ## Configuration file for PLP features
                         ## (string, default = "")
################################################################################
